Module 4 - Clustering
Lab Code Practice
 
***4.2.1 Lab - k-Means***

import random
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.datasets.samples_generator import make_blobs
%matplotlib inline

np.random.seed(0)

X, y = make_blobs(n_samples = 5000, centers = [[4, 4], [-2, -1], [2, -3], [1, 1]], cluster_std = 0.9)

plt.scatter(X[:,0], X[:,1], marker = '.')

k_means = Kmeans(init = 'k-means++', n_clusters = 4, n_init = 12)

k_means.fit(X)

k_means_labels = k_means.lables_
k_means_labels

k_means_cluster_centers = k_means.cluster_centers_
k_means_cluster_centers

fig = plt.figure(figsize = (6, 4))
colors = plt.cm.Spectral(np.linspace(0, 1, len(set(k_means_labels))))
ax = fig.add_subplot(1, 1, 1)
for k, col in zip(range(len([[4, 4], [-2, -1], [2, -3], [1, 1]])), colors):
    my_members = (k_means_labels == k)
    cluster_center = k_means_cluster_centers[k]
    ax.plot(X[my_members, 0], X[my_members, 1], 'w', markerfacecolor = col, marker = '.')
    ax.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor = col, markeredgecolor = 'k', markersize = 6)
ax.set_title('KMeans')
ax.set_xticks(())
ax.set_yticks(())
plt.show()

k_means3 = KMeans(init = 'k-means++', n_clusters = 3, n_init = 12)
k_means3.fit(X)
fig = plt.figure(figsize = (6, 4))
colors = plt.cm.Spectral(np.linspace(0, 1, len(set(k_means3.labels_))))
ax = fig.add_subplot(1, 1, 1)
for k, col in zip(range(len(k_means3.cluster_centers_)), colors):
    my_members = (k_means3.labels_ == k)
    cluster_center = k_means3.cluster_centers_[k]
    ax.plot(X[my_members, 0], X[my_members, 1], 'w', markerfacecolor = col, marker = '.')
    ax.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor = col, markeredgecolor = 'k', markersize = 6)
plt.show()

import panadas as pd
cust_df = pd.read_csv('4.3.1 Cust_Segmentation.csv')
cust_df.head()

df+cust_df.drop('Address', axis = 1)
df.head()

from sklearn.preprocessing import StandardScaler
X = df.values[:, 1:]
X = np.nan_to_num(X)
Clus_dataSet = StandardScaler().fit_transform(X)
Clus_dataSet

clusterNum = 3
k_means = KMeans(init = 'k-means++', n_clusters = clusterNum, n_init = 12)
k_means.fit(X)
labels = k_means.labels_
print(labels)

df['Clus_km'] = labels
df.head(5)

df.groupby('Clus_km').mean()

area = np.pi * (X[:, 1]) ** 2
plt.scatter(X[:, 0], X[: 3], s = area, c = labels.astype(np.float), alpha = 0.5)
plt.xlabel('Age', fontsize = 18)
plt.ylabel('Income', fontsize = 16)
plt.show()

from mpl_toolkits.mplot3d import Axes3D
fig = plt.figure(1, figsize = (8, 6))
plt.clf()
ax  = Axes3D(fig, rect = [0, 0, .95, 1], elev = 48, azim = 134)
plt.cla()
plt.set_xlabel('Education')
plt.set_ylabel('Age')
plt.set_zlabel('Income')
ax.scatter(X[:, 1], X[:, 0], X[:, 3], c = labels.astype(np.float))



***4.2.2 Lab - Agglomerative Clustering***

import numpy as np
import pandas as pd
from scipy import ndimage
from scipy.cluster import hierarchy
from scipy.spatial import distance matrix
from matplotlib import pyplot as plt
from sklearn import pyplot as plt
from sklearn.cluster import AgglomerativeClustering
from sklearn.datasets.samples_generator import make_blobs
%matplotlib inline

X1, y1 = make_blobs(n_samples = 50, centers = [[4, 4], [-2, -1], [1,1], [10, 4]], cluster_std = 0.9)

plt.scatter(X1[:, 0], X1[:, 1], marker = 'o')

agglom = AgglomerativeClustering(n_clusters = 4, linkage = 'complete')

agglom.fit(X1, y1)

plt.figure(figsize = (6, 4))
x_min, x_max = np.min(X1, axis = 0), np.max(X1, axis =0)
X1, = (X1 - X_min) / (x_max - x_min)
for i in range(X1.shape[0]):
    plt.text(X1[i, 0], X1[i, 1], str(y1[i]),
             color = plt.cm.nipy_spectral(agglom.labels_[i] / 10.),
             fontdict = {'weight': 'bold', 'size': 9})
plt.xticks([])
plt.yticks([])
plt.scatter(X1[:, 0], X1[:, 1], marker = '.')
plt.show()

dist_matrix = distance_matrix(X1, X1)
print(dist_matrix)

Z = hierarchy.linkage(dist_matrix, 'complete')

dendro = hierarchy.dendrogram(Z)

filename = '4.3.2 cars_clus.csv'
pdf = pd.read_csv(filename)
print('Shape of dataset: ', pdf.shape)
pdf.head(5)

print('Shape of dataset before cleaning: ', pdf.size)
pdf[['sales', 'resale', 'type', 'price', 'engine_s', 'horsepow', 'wheelbas', 'width', 'length', 'curb_wgt', 'fuel_cap', 'mpg', lnsales']] = pdf[['sales', 'resale', 'type', 'price', 'engine_s', 'horsepow', 'wheel_bas', 'width', 'length', 'curb_wgt', 'fuel_cap', 'mpg', lnsales']].apply(pd.to_numeric, errors = 'coerce')
pdf = pdf.dropna()
pdr = pdf.reset_index(drop = True)
print('Shape of dataset after cleaning: ', pdf.size)
pdf.head(5)

featureset = pdf[['engine_s', 'horsepow', 'wheelbas', 'width', 'length', 'curb_wgt', 'fuel_cap', 'mpg']]

from sklearn.preprocessing import MinMaxScaler
x = featureset.values
min_max_scaler = MinMaxScaler()
feature_mtx = min_max_scaler.fit_transform(x)
feature_mtx [0:5]

import scipy
leng = feature_mtx.shape[0]
D = scipy.zeros([leng, leng])
for i in range(leng):
    for j in range (leng):
        D[i, j] = scipy.spatial.distance.euclidean(feature_mtx,[i], feature_mtx[j])
D

import pylab
iport scipy.cluster.hierarchy
Z = hierarchy.linkage(D, 'complete')

from scipy.cluster.hierarchy import fcluster
max_d = 3
clusters = fcluster(Z, max_d, criterion = 'distance')
clusters

from scipy.cluster.hierarchy import fcluster
k = 5
clusters = fcluster(Z, k, criterion = 'maxclust')
clusters

fig = pylab.figure(figsize = (18, 50))
def llf(id):
    return '[%s %s %s]' % (pdf['manufact'][id], pdf['model'][id], int(float(pdf['type'][id])))
dendro = hierarcy.dendrogram(Z, leaf_label_func = llf, leaf_rotation = 0, leaf_font_size = 12, orientation = 'right')

from sklearn.metrics.pariwise import euclidean distances
dist_matrix = euclidean_distances(feature_mtx, feature_mtx)
print(dist_matrix)

Z_using_dist_matrix = hierarchy.linkage(dist_matrix, 'complete')

fig = pylab.figure(figsize = (18, 50))
def llf(id):
    return '[%s %s %s]' % (pdf['manufact'][id], pdf['model'][id], int(float(pdf['type'][id])))
dendro = hierarchy.dendrogram(Z_using_dist_matrix, leaf_label_func = llf, leaf_rotation = 0, leaf_font_size = 12, orientation = 'right')

agglom = AgglomerativeClustering(n_clusters = 6, linkage = 'complete')
agglom.fit(dist_matrix)
agglom.labels_

pdf['cluster_'] = agglom.labels_
pdf.head()

import matplotlib.cm as cm
n_clusters = max(agglom.labels_) + 1
colors = cm.rainbow(np.linsapce(0, 1, n_clusters))
cluster_labels = list(range(0, n_clusters))
plt.figure(figsize = (16,14))
for color, label in zip(colors, cluster_labels):
    subset = pdf[pdf.cluser_ == label]
    for i in subset.index:
        plt.text(subset.horsepow[i], subset.mpg[i], str(subset['model'][i]), rotation = 25)
    plt.scatter(subset.horsepow, subset.mpg, s = subset.price * 10, color, label = 'cluster' + str(label), alpha = 0.5)
plt.legend()
plt.title('Clusters')
plt.xlabel('horsepow')
plt.ylabel('mpg')

pdf.groupby(['cluster_', 'type'])['cluster_'].count()

agg_cars = pdf.groupby(['cluster', 'type'])['horsepow', 'engine_s', 'mpg', 'price']
agg_cars

plt.figure(figsize = (16, 10))
for color, label in zip(colors, cluster_labels):
    subset = agg_cars.loc[(label,),]
    for i in subset.index:
        plt.text(subset.loc[i][0] + 5, subset.loc[i][2], 'type='+str(int(i)) + ', price =' + str(int(subset.loc[i][3])) + 'k')
    plt.scatter(subset.horsepow, subset.mpg, s = subset.price * 20, c = color, label = 'cluster' + str(label))
plt.legend()
plt.title('Clusters')
plt.xlabel('horsepow')
plt.ylabel('mpg')



***4.2.3 Lab - DBSCAN Clustering***

I HAD A REALLY DIFFICULT TIME WITH THE BASEMAP PACKAGE. I SPENT MORE TIME IN THE COMMAND LINE TRYING TO SOLVE ISSUES RUNNING THE PACKAGE THEN I SPENT FOCUSED ON THE LAB.

IN THE END I DECIDED TO MOVE ON WITHOUT IT DESPITE THAT IT BREAKS THE VISUALIZATIONS FOR THIS LAB


!conda install -c conda-forge basemap matplotlib == 3.1 -y

import numpy as np
from sklearn.cluster import DBSCAN
from sklearn.datasets import make_blobs
from sklearn.preprocessing import StandardScaler
import maplotlib.pyplot as plt
%matplotlib inline

def createDataPoints(centroidLocation, numSamples, clusterDeviation):
    X,y = make_blobs(n_samples = numSamples, centers = centroidLocation, cluster_std = clusterDeviation)
    X = StandardScaler().fit_transfomr(X)
    return X, y
    
X, y = createDataPoints([[4, 3], [2, -1], [-1, 4]], 1500, 0.5)

epsilon = 0.3
minimumSamples = 7
db = DBSCAN(eps = epsilon, min_samples = minimumSamples).fit(X)
labels = db.labels_
labels

core_samples_mask = np.zeros_like(db.labels_, dtype = bool)
core_samples_mask[db.core_sample_indices_] = True
core_samples_mask

n_clusters_ - len(set(labels)) - (1 if - 1 in labels else 0)
n_clusters_

unique_labels = set(labels)
unique_lables

colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))
for k, col in zip(unique_labels, colors):
    if k == - 1:
        col = 'k'
    class_member_mask = (labels == k)
    xy = X[class_member_mask & core_samples_mask]
    plt.scatter(xy[:, 0], xy[:, 1], s = 50, c = [col], marker = u'o', alpha = 0.5)
    xy = X[class_member_mask & ~core_samples_mask]
    plt.scatter(xy[:, 0], xy[:, 1], s = 50, c = [col], marker = u'o', alpha = 0.5)
    
from skleanr.cluster import KMeans
k = 3
k_means = KMeans(init = 'k-means++', n_clusters = k, n_init = 12)
k_means.fit(X)
fig = plt.figure(figsize = (6, 4))
ax = fig.add_subplot(1, 1, 1)
for k, col in zip(range(k), colors):
    my_members = (k_means.labels_ == k)
    plt.scatter(X[my_members, 0], X[my_members, 1], c = col, marker = u'o', alpha  = 0.5)
plt.show()

import csv
import pandas as pd
import numpy as np
filename = '4.3.3 weather-stations20140101-10141231.csv'
pdf.pd.read_csv(filename)
pdf.head(5)

pdf = pdf[pd.notnull(pdf["Tm"])]
pdf = pdf.reset_index(drop = True)
pdf.head(5)

from mpl_toolkits.basemap import Basemap
import matplotlib.pyplot as plt
from pylab import rcParams
%matplotlib inline
rcParams['figure.figsize'] = (14,10)

llon = -140
ulon = -50
llat = 40
ulat = 65

pdf = pdf[(pdf['Long'] > llon) & (pdf['Long'] < ulon) & (pdf['Lat'] > llat & (pdf['Lat'] < ulat))]
my_map = Basemap(projection = 'merc',
                 resolution = 'l', area_thresh = 1000,
                 llcrnrlon = llon, llcrnrlat = llat,
                 urcrnrlon = ulon, urcrnrlat = ulat)
my_map.drawcoastlines()
my_map.drawcountries()
my_map.fillcontinents(color = 'white', alpha = 0.3)
my_map.shadedrelief()
xs, ys = my_map(np.asarray(pdf.Long), np.asarray(pdf.Lat))
pdf['xm'] = xs.tolist()
pdf['ym'] = ys.tolist()
for index, row in pdf.iterrows();
    my_map.plot(row.xm, row.ym, markerfacecolor = ([1,0,0]), marker = 'o', markersize = 5, alpha = 0.75)
plt.show()

from sklearn.cluster import DBSCAN
import sklean.utils
from sklean.preprocessing import StandardScaler
sklearn.utils.check_random_state(1000)
Clus_dataSet = pdf[['xm', 'ym']]
Clus_dataSet = np.nan_to_num(Clus_dataSet)
Clus_dataSet = StandardScaler().fit_transform(Clus_dataSet)
db = DBSCAN(eps = 0.15, min_samples = 10).fit(Clus_dataSet)
core_samples_mask = np.zeros_like(db.labels_, dtype = bool)
core_samples_mask[db.core_sample_indices_] = True
labels = db.labels_
pdf["Clus_Db"] = Labels
realClusterNum = len(set(labels)) - (1 if -1 in labels else 0)
clusterNum = len(set(labels))
pdf[['Stn', 'Tx', 'Tm', 'Clus_Db']]. head(5)

set(labels)

from mpl_toolkits.basemap import Basemap
import matplotlib.pyplot as plt
from pylab import rcParams
%matplotlib inline
rcParams['figure.figsize'] = (14, 10)
my_map = Basemap(projection = 'merc',
                 resolution = '1', area_thresh = 1000,
                 llcrnrlon = llon, llcrnrlat = llat,
                 urcrnrlon = ulon, urcrnrlat = ulat)           
my_map.drawcoastlines()
my_map.drawcountries()
my_map.fillcontinents(colore = 'white', alpha = 0.3)
my_map.shadedrelief()
colors = plt.get_cmap('jet')(np.linspace(0.0, 1.0, clusterNum))
for clust_number in set(labels):
    c = (([0.4, 0.4, 0.4]) if clust_number == -1 else colors[np.int(clust_number)])
    clust_set = pdf[pdf.Clus_Db == clust_number]
    my_map.scatter(clust_set.xm, clust_set.ym, color = c, marker = 'o', s = 20, alpha = 0.85)
    if clust_number != -1;
    cenx = np.mean(clust_set.xm)
    ceny = np.mean(clust_set.ym)
    plt.text(cenx, ceny, str(clust_number), fontsize = 25, color = 'red',)
    print('Cluster' + str(clust_number) + ', Avg Temp: ' + str(np.mean(clust_set.Tm)))
    
from sklearn.cluster import DBSCAN
import sklearn.utils
from sklearn.preprocessing import StandardScaler
sklearn.utils.check_random_state(1000)
Clus_dataSet = pdf[['xm', 'ym', 'Tx', 'Tm', 'Tn']]
Clus_dataSet = np.nan_to_num(Clus_dataSet)
Clus_dataSet = StandardScaler().fit_transform(Clus_dataSet)
db = DBSCAN(eps = 0.15, min_samples = 10).fit(Clus_dataSet)
core_samples_mask = np.zeros_like(db.labels_, dtype = bool)
core_samples_mask[db.core_sample_indices_] = True
labels = db.labels_
pdf['Clus_Db'] = labels
realClusterNum = len(set(labels)) - (1 if -1 in labels else 0)
clusterNum = len(set(labels))
pdf[['Stn_name', 'Tx', 'Tm', 'Clus_Db']].head()

from mpl_toolkits.basemap import Basemap
import matplotlib.pyplot as plt
from pylab import rcParams
%matplotlib inline
rcParams['figure.figsize'] = (14,10)
my_map = Basemap(projection = 'merc',
                 resolution = '1', area_thresh = 1000.0,
                 llcrnrlon = llon, llcrnrlat = llat,
                 urcrnrlon = ulon, urcrnrlat = ulat)
my_map.drawcoastlines()
my_map.drawcountries()
my_map.fillcontinents(color = 'white', alpha = 0.3)
my_map.shadedrelief()
colors = plt.get_cmap('jet')(np.linspace(0.0, 1.0, clusterNum))
for clust_number in set(labels):
    c = (([0.4, 0.4, 0.4]) if clust_number == -1 else colors[np.int(clust_number)])
    clust_set = pdf[pdf.Clus_Db == clust_number]
    my_map.scatter(clust_set.xm, clust_set.ym, color = c, marker = 'o', s = 20, alpha = 0.85)
    if clust_number != 1:
        cenx = np.mean(clust_set.xm)
        ceny = np.mean(clust_set.ym)
        plt.text(cenx, ceny, str(clust_number), fontsize = 25, color = 'red',)
        print('Cluster ' + str(clust_number) + ', Avg Temp: ' + str(np.mean(clust_set.Tm)))